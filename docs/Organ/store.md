### 存储系统层次结构

基本的存储体系：存储程序与程序控制。基本过程有：

- 输入设备将程序与数据写入主存
- CPU取指令
- CPU执行指令期间读数据
- CPU写回运算结果
- 输出设备输出结果

主存速度慢的原因：

- 主存增速与CPU赠速不同步：前者每年60%，后者每年7%左右，主存的速度慢使CPU性能下降。
- 指令执行期间会多次访问存储器：取指令、读数据、写结果。

主存容量不足的原因：

- 存在制约主存容量的技术因素，由CPU、主板等相关技术指标确定。比如CPU地址位数等。
- 应用对主存的需求不断扩大。
- 价格原因：价格太高

由上述分析可见，在计算机系统中面临着主存速度和容量不够的问题，构建存储体系是解决这个问题的有效方法。

原本的冯诺伊曼体系结构有CPU和存储器，我们可以加上辅助存储器（磁盘、磁带、网络存储等）来解决主存容量不足与高成本之间的矛盾，在CPU与主存之间加上Cache解决CPU与主存速度不匹配的矛盾。这样就构成了存储体系的层次化结构，如下图所示。

![存储体系的层次化结构](http://book.moecode.com/store/1.png)

CPU与层次结构的关系可以这样看：从左到右分别是CPU->Cache->主存->辅存。那么对于CPU来说，其访问到的存储系统具有Cache的速度，辅存的容量和价格。

随着技术的发展，Cache也可以分为两部分：

- L1 Cache集成在CPU中，分为数据Cache（D-Cache）和指令Cache（I-Cache）。
- 早期L2 Cache在主板上或与CPU集成在同一电路板上。随着工艺的提高L2 Cache被集成在CPU内核中，不分D-Cache和I-Cache。

那这样的存储系统体系结构为什么能够很好地工作呢？其理论基础是局部性原理：

- 时间局部性：当前被访问的信息在不久的将来还将再次被访问。在程序结构中的体现是循环结构。
- 空间局部性：当前被访问的信息的附近的信息在不久的将来会被访问。在程序结构中的体现是顺序结构。

由局部性原理可知，将整块数据段/代码段放入Cache可以大大提升性能。可初步体会存储系统中软硬件的协同。



### 主存中的数据组织

存储字长：主存中的一个存储单元所包含的二进制的位数。目前大多数计算机的主存按字节编址，存储字长也不断扩大，比如16位字长、32位字长、64位字长等。32位字长表示主存的一个单元包含4个字节（32bit）的数据。

指令集体系结构ISA设计时需要考虑两个问题：

- 如何根据字节地址读取一个32位的字？（注意这里的“字”与机器字长有关）这有关字的存放问题。
- 一个字能否存放在主存的任何字节边界？字的边界对齐问题。

先考虑对齐问题，按边界和未按边界对齐的数据存储举例如下：

![按边界对齐](http://book.moecode.com/store/2.png)

![未按边界对齐](http://book.moecode.com/store/3.png)

在上面的两个例子中，变量x在按边界对齐的情况下需要访存2次，而在未按边界对齐的情况下需要访存3次。可见未按边界的方法虽然节省了空间但是增加了访存的次数（访存是一个个单元来访问的），这是用性能换取空间。

在32位系统中：

- 双字长数据边界对齐的起始地址最末三位为000（32位机中双字为8字节）
- 单字节边界对齐的起始地址的最末二位为00
- 半字节边界对齐的起始地址的最末一位为0

考虑数据的存放方式：大端与小端存储方式

Big-endian：最高字节地址（MSB）是数据地址，比如IBM 360/370、MIPS。

Little-endian：最低字节地址（LSB）是数据地址，比如Intel 80x86。

![例题](http://book.moecode.com/store/4.png)



### 静态存储器的工作原理

SRAM存储单元的工作原理涉及过多模电知识，此处省略。要注意的是只有X地址译码线和Y地址译码线都有效时存储单元才能正常工作。

静态存储器的结构分为单译码结构和双译码结构，如下图所示。在双译码结构中将地址分为X地址译码和Y地址译码两个部分，考虑X和Y均分的情况，N位地址仍能寻址2^n个存储单元（2^(n/2) * 2^(n/2)），但是所需译码线的数量大大减少。

![静态存储器的结构](http://book.moecode.com/store/5.png)

由于双译码结构中一行或一列带有多个单元，所以需要添加驱动电路以维持电路的正常运行。一种采用双译码结构的存储器内部结构如下图所示。

![内部结构举例](http://book.moecode.com/store/6.png)

两款实际的芯片外部接口如图所示。2114的读写控制比6116更简单。从外部引脚看不出行列分别有多少位。

![6116](http://book.moecode.com/store/7.png)

![2114](http://book.moecode.com/store/8.png)

2114的内部结构如下图所示。

![2114结构](http://book.moecode.com/store/9.png)



### 动态存储器工作原理

SRAM存储单元（静态存储器）的不足：晶体管过多，容量难以做大；存储密度低；功耗过大，因为饱和导通电流大，热效应明显。所以静态存储器芯片的容量比较小。

改进后可以得到DRAM动态存储单元。具体分析省略。DRAM的读过程比写复杂，速度慢。可见动态存储器的速度比相同功率下的静态存储器的速度要慢。

DRAM比SRAM多了刷新操作。刷新周期：两次刷新之间的时间间隔。双译码结构的DRAM刷新按行进行，需要知道DRAM芯片存储矩阵的行数（只需给出X地址译码线）。刷新地址由刷新地址计数器给出，不能有CPU给出，因为要遍历每一行。

用一个例子来考虑DRAM存储单元的刷新。假定刷新周期为2ms（表示每个单元在2ms内需要刷新一次），DRAM内部128行（DRAM按行刷新），读写周期0.5微秒。

第一种方法是集中刷新。2ms除以0.5微秒为4000，2ms之内要进行128次行刷新。如下图所示，3872个时间段正常读写，128个时间段进行刷新不能够读写。平均读写周期与原来的0.5微秒相差不多。可见：集中刷新可以保持存储单体的高速特性。缺点是存在大段的不能读写的时间，所以对于实时要求比较高的场合不适合使用集中刷新。

![集中刷新](http://book.moecode.com/store/10.png)

第二种是分散刷新。分散刷新指的是读写一次就刷新一次，所以2ms之内由2000次行刷新操作。平均读写周期变为1微秒。可见高速特性没有得到保留。

![分散刷新](http://book.moecode.com/store/11.png)

第三种是异步刷新。将2ms分成128段，每一段15.5微秒，前面的15微秒用来进行正常的读写操作，后面的0.5微秒用来刷新一行。这样既保证了128行的遍历刷新，又保证了存储单体的高速特性。异步刷新的平均读写周期与集中式刷新一样。

![异步刷新](http://book.moecode.com/store/12.png)

2114是静态的，2116是动态的，二者的对比如下。2116相比2114多了行选通和列选通RAS/CAS，因为刷新的时候是按行刷新的，不需要列选通。此外DRAM采用了地址线复用，也就是行和列地址是分开送进去的。比如2116容量16K应该有14个地址位，但是芯片引脚的地址位数只有7位，可见行列是分开送的。

![对比图](http://book.moecode.com/store/13.png)



### 存储扩展

存储单体的容量或字长是不够的，所以需要进行存储扩展或者说主存的组织。

- 连接的地址线的数量与CPU要访问的主存容量有关
- 连接的数据线数量与计算机字长有关
- 对于RAM而言，控制线包括片选信号和读写控制，而对于ROM而言则只有片选信号线
- DRAM没有片选控制线，进行容量扩展时利用RAS和CAS控制芯片的选择

存储器的位扩展、字扩展和字位扩展如下图所示。其中M表示容量，N表示字长。

![存储扩展示意图](http://book.moecode.com/store/14.png)

当存储芯片的数据位小于CPU对数据位的要求时，采用位扩展。位扩展时将所有存储芯片的地址线、读写控制线并联同时分别与CPU的地址线和读写控制线相连接；存储芯片的数据线依次与CPU的数据线相连；所有芯片的片选控制线（CS上面加一横线）并联接低电平（低电平有效，片选表示该片有效）。举例如下：

![位扩展举例](http://book.moecode.com/store/15.png)

要注意的是由于数据的对齐，CPU地址中的低两位是不需要送入存储器的，所以存储器连接的实际是A的2-15，刚好14位对应16K的存储空间。为什么是低两位？因为字长32bit，4字节，刚好对应低2位。

字扩展也称容量扩展。当存储芯片的存储容量不能满足存储器对存储容量的要求时，可采用字扩展方式来扩展存储器。字扩展时，将所有存储芯片的数据线、读写控制线各自并联同时分别与CPU的数据线和读写控制线连接；各存储芯片的片选信号由CPU多余的地址线产生。举两例如下：

![字扩展举例1](http://book.moecode.com/store/16.png)

![字扩展举例2](http://book.moecode.com/store/17.png)

![字扩展举例3](http://book.moecode.com/store/18.png)

![字扩展举例4](http://book.moecode.com/store/19.png)

注意上面四张图都是8位一个字节而已，而计算机按字节编码，所以不需要考虑对齐的问题。

字位同时扩展举例如下。要同时考虑数据对齐和片选信号。

![字位扩展举例](http://book.moecode.com/store/20.png)



### 测验总结1

1. 判断：采用虚拟内存技术后程序可以直接在硬盘上运行。（错）
2. 判断：内存的存取速度不能低于CPU速度，否则会造成数据丢失。（错）
3. RAM和ROM都采用随机存取的方式进行访问。“RAM和ROM都不需要刷新”的说法是错的。
4. 存储周期和存储容量属于衡量存储器技术指标。
5. DRAM比SRAM慢可能的原因：DRAM需要刷新；DRAM存储体行列地址线复用（输入2次）；DRAM读之前需要预充电。
6. DRAM、Flash Memory、EPROM、SRAM中速度最快的是SRAM，只有DRAM需要定时刷新。



### 多体交叉存储器

基本思想是在不提高存储器速率、不扩展数据总线位数的前提下，通过存储芯片的交叉组织，提高CPU单位时间内访问的数据量，从而缓解快速的CPU与慢速的主存之间的速度差异。这是不同于Cache的一种缓解速度矛盾的方式。

高位多体交叉存储器如下所示。由局部性原理可知CPU取相邻的数据，在高位多体交叉的情况下仍是连续访问同一组，性能仍收到存储器的限制。

![高位](http://book.moecode.com/store/21.png)

低位多体交叉存储器如下所示。当CPU取相邻的数据时，可以到不同的片中取，尽管存储单体的速度慢，但是这种情况下表现为并行运行。

![低位](http://book.moecode.com/store/22.png)

进一步解释低位多体交叉存储器的工作方式：通过4个存储体的并行工作，可以实现对存储器的流水线方式访问。计算如下图所示。

![低位计算](http://book.moecode.com/store/23.png)



### Cache的基本原理

Cache：高速缓冲存储器。功能：缓解快速CPU与慢速的主存之间的速度差异。Cache的理论基础：局部性原理。主存与辅存之间也可能有Cache用来缓解速度的矛盾。这里讲的主要是CPU与主存之间的Cache。

考虑CPU从Cache中读数据的过程，如果CPU所需的数据正好在Cache中叫做“命中”，命中时要解决两个问题：如何判断数据在Cache中？Cache中的数据是有效的吗？（其他设备可能通过DMA操作修改主存）

如果CPU所需的数据不在Cache中称为“缺失”，那么主存需要讲其所需的数据直接送给CPU，同时将那一行送到Cache中。可见缺失造成访问速度的急剧下降。

注意：CPU与Cache之间以字为单位交换数据，Cache与主存之间交换数据是一块一块地进行的。

![Cache的读操作](http://book.moecode.com/store/24.png)

讨论Cache的写操作，有两种策略。

- 写穿策略（Write Through）：CPU得到的结果既写到Cache中又写到主存中，由主存返回写响应，这种策略没有体现Cache的高速特性。
- 写回策略（Write Back）：CPU得到的结果先写到Cache，由Cache返回写响应，当一组数据写完后再一起写到主存中，这充分利用了Cache的高速特性。

但是写回策略存在这样的问题：DMA操作需要从主存中读取数据，而最新的数据还在Cache中，没法得到最新数据。后面设计的时候进行详述。

Cache的结构如下图所示。

![Cache结构](http://book.moecode.com/store/25.png)

主存和缓存的编址如下图所示。主存储器有M个字块，每个字块有B个字，地址可以分成两段（二维地址），分别为m位和b位，称主存块号和块内地址。Cache也进行类似的划分，有M>>C。Cache的命中率定义为CPU欲访问的信息在Cache中的比率，效率定义为访问Cache的时间与访问主存的时间之比，计算关系如下图所示。

![效率的计算](http://book.moecode.com/store/26.png)

Cache的基本结构如下图所示。中间是Cache部分，获得CPU要访问的地址后将其分为块号和块内地址两个部分，块内地址保持不变（因为Cache和主存一行的长度是一样的），对块号进行判断是否命中，如果命中则与块内地址连接送入Cache存储体读取数据；如果不命中则查看是否能直接装入Cache，如果可以就访问主存装入Cache（一边送入CPU一边写入Cache），如果不行就使用替换算法。

![Cache的基本结构](http://book.moecode.com/store/27.png)



### Cache地址映射与变换方法

注意：“Cache容量”没有特别说明时指的是数据区的容量。

直接映射示意图如下。主存地址的前m位块号分为两部分，即取出c位作为Cache字块地址，表示字块在Cache中的顺序，剩余t=m-c位是主存字块标记。将主存按Cache的长度划分成2^t个区，每个区有2^c个块，每个区中第i个块可以存储到Cache的第i个块中。Cache中每个块前面有对应的字块标记，表示其在主存中是第几个区中。当CPU给出地址需要查询数据时先将地址划分成三个区，按中间的Cache字块地址找到Cache中对应的字块，看其标记与主存字块标记是否相等，如果相等表示命中，否则不命中。

![直接相连](http://book.moecode.com/store/28.png)

直接相连的特点是：每个缓存块可以与若干个主存块对应，每个主存块只能和一个缓存块对应。这样就导致命中率不高。

全相联映射走向另一个极端，如下图所示。每个主存中的字块可以存到Cache中的任意字块，这样一来主存字块标记长度也就上升到m位。全相联映射的特点是：主存中的任一块可以映射到缓存中的任一块。当CPU给出地址，将其分成两段，前面m位是主存字块标记，要与Cache中的每一个标记进行比较。可见全相联的缺点是比较过于复杂。

![全相联](http://book.moecode.com/store/29.png)

组相联映射是以上两种方法的折中，如下图所示。主存地址的前m位分为两部分，s位为主存字块标记，q位为组地址（第几组）。Cache共Q组，每组有2块；主存按Cache的组数进行分区，每个区Q个字块，共S个区。主存中每个区的第i个字块可以存放到Cache中第i组的若干个字块中。

![组相联](http://book.moecode.com/store/30.png)

组相联映射的特点是：i = j mod Q，某一主存块 j 按模Q映射到缓存中第 i 组中的任一块。

三种方法的关系：如果每个组只有一个块，则退化成直接相连；如果只有一个组则称为全相联。
