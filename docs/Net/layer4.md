### 传输层服务概述

传输层协议为运行在不同主机上的进程提供了一种逻辑通信机制（两个进程之间仿佛是直接连接的，也就是端到端的）。路由器只有网络层及以下的层次。

端系统运行传输层协议，发送方将应用递交的消息分成一个或多个报文段，并向下传给网络层；接收方则将收到的报文段组装成消息，向上交给应用层。传输层可以为应用提供多种传输层协议（UDP/TCP）。

网络层提供主机之间的逻辑通信机制，而传输层提供应用进程之间的逻辑通信机制。传输层依赖于网络层服务，对网络层服务进行可能的增强。

TCP提供可靠、按序的交付服务；UDP提供尽力而为“Best-effort”的服务（比如多路分用/多路复用）。两种服务均不保障延迟和带宽。



### 多路复用和多路分用

这是网络传输的必要功能。如果某层的一个协议直接对应上层的多个协议或实体，则需要进行复用/分用。

- 接收端进行多路分用：传输层依据头部信息将收到的Segment交给正确的Socket，即不同的进程。

- 发送端进行多路复用：从多个Socket接收数据，为每个块的数据封装上头部信息，生成Segment，交给网络层。

多路分用如何工作？主机接收到IP数据报，每个数据报携带源IP地址、目的IP地址；每个数据报携带一个传输层的段，每个段携带源端口号和目的端口号。主机收到Segment后，传输层协议提取IP地址和端口号信息，将Segment导向相应的Socket。

要注意的是上面的描述中，数据报是网络层的概念，数据报带的是IP地址；报文段是传输层的概念，报文段带的是端口号。

无连接的多路分用。UDP的Socket用一个二元组来标识（目的IP地址，目的端口号），主机收到UDP段之后会检查段中的目的端口号，将UDP段导向绑定在该端口号的Socket。来自不同源IP地址或源端口号的IP数据报被导向同一个Socket。

![无连接分用](http://book.moecode.com/layer4/1.png)

面向连接的多路分用。TCP的Socket用四元组来标识（源IP地址，源端口号，目的IP地址，目的端口号），接收端利用所有的四个值将Segment导向合适的Socket，服务器可能同时支持多个TCP Socket。

![面向连接的分用](http://book.moecode.com/layer4/2.png)

为什么面向连接的分用要用四元组来标识呢？如上图所示，中间的服务器C有一个Web服务器进程（端口号是80），其对于每一个客户端都需要开辟一个socket（TCP连接是一对一的）。客户B有两个客户端进程P2和P3，如果他们的socket和UDP一样是二元组标识的，那么目的IP和目的端口都是一样的，这两个socket就无法区分，如果用四元组来标识，那么二者的源端口号就不一样，TCP的socket就不一样。

多线程Web服务器的多个线程对应不同的socket，如下图所示。可见socket和进程不一定一一对应。

![多线程Web服务器](http://book.moecode.com/layer4/3.png)



### UDP

UDP全称User Datagram Protocol [RFC 768]，基于Internet IP协议，实现的是传输层最简单必要的功能（多路复用/分用，简单的错误校验）。UDP提供“Best effort”服务，所以UDP段有可能丢失，也有可能非按序到达。UDP还有无连接的特点，UDP的发送方和接收方之间不需要进行握手，由于无连接的特点，每个UDP段的处理独立于其他的段。在传输层实现错误检测功能依据的是端到端的原则。

为什么UDP会存在（相比于TCP的功能来说显得那么少）？

- UDP无需建立连接从而能够减少延迟。
- UDP无需维护连接状态，所以实现起来更简单
- UDP协议简单所以头部开销少，UDP是8个字节的头部，而TCP是20个字节。
- UDP没有拥塞控制，所以应用能够更好地控制发送时间和速率（对于需要更好地掌控时间的应用可以使用UDP）。

UDP的应用：

- 流式媒体：容忍丢失且对速率敏感。
- DNS和SNMP。

UDP没有实现可靠传输，但是我们仍能够在应用层增加可靠性机制，以及特定的错误恢复机制，所以应用开发的难度是比较大的。

UDP报文段格式：目的和源端口号分别是2个字节，报文段长度2字节，校验和2字节。

![UDP报文段头部](http://book.moecode.com/layer4/4.png)

UDP校验和：目的在于检测UDP段在传输过程中是否发生了错误（比如位翻转）。发送方要计算校验和并放入校验和字段，

![UDP校验和计算流程](http://book.moecode.com/layer4/5.png)

![校验和计算举例](http://book.moecode.com/layer4/6.png)



### 可靠数据传输原理

什么是可靠？不错、不丢、不乱。可靠数据传输对于应用层、传输层、链路层都很重要，是计算机网络TOP10问题。信道的不可靠特性决定了可靠数据传输协议（rdt）的复杂性。可靠数据传输的基本结构（接口）如下图所示：

![RDT接口](http://book.moecode.com/layer4/7.png)

注意左上角和右上角的箭头是单向的，因为应用层不关心下面的实现。而rdt和下面的接口是双向的箭头。

下面将渐进地设计可靠数据传输协议的发送方和接收方。一个重要的假设：只考虑单向的数据传输，但是控制信息是可以双向流动的。利用有限状态机来刻画传输协议。圆圈表示状态，箭头表示状态的迁移，箭头上的横线上方是引起状态变迁的事件，横线下方是变迁发生时的活动。

Rdt1.0:可靠信道上的可靠数据传输。底层信道完全可靠：不会发生错误，不会丢弃分组。由于可靠，所以两边不用发送控制信息，进一步使得发送方和接收方的FSM是相对独立的。

![Rdt1.0](http://book.moecode.com/layer4/8.png)



### Rdt2.0

考虑只产生位错误的信道（分组不丢失、按序到达）。利用校验和来检测位错误，但如何从错误中恢复呢？如果发生错误，发送方是不确定有没有发生错误的，所以接收方需要显式地告知发送方是否收到已经是否发生错误。

引入ACK、NAK、重传机制。ACK是接收方显式地告知发送方分组已经正确接收，NAK是接收方显式地告知发送方分组有错误。发送方收到NAK后就会进行重传。这种基于重传机制的rdt协议称为ARQ（Automatic Repeat reQuest）协议。

总结Rdt2.0中引入的新机制：

- 差错检测
- 接收方反馈控制消息：ACK/NAK
- 重传机制

如何设计？用FSM规约。Rdt2.0体现为停-等协议。

![Rdt2.0](http://book.moecode.com/layer4/9.png)



### Rdt2.1和2.2

Rdt2.0的缺陷：如果ACK/NAK消息发生错误/被破坏怎么办？几种可能的方案：

- 为ACK/NAK增加校验和，检错并纠错。纠错实现起来比较复杂。
- 发送方接收到被破坏ACK/NAK时不知道接收方发生了什么，添加额外的控制消息。但是这样发回去的控制消息仍可能错误。
- 如果ACK/NAK坏掉，可以让发送方重传，但是不能简单地重传，因为可能发生分组的重复。

如何解决重复分组问题？可以给每个增加序列号，这样就得到Rdt2.1。Rdt2.1的发送方和接收方的FSM如下图所示。

![发送方](http://book.moecode.com/layer4/10.png)



![接收方](http://book.moecode.com/layer4/11.png)

需要特别注意：接收方中“Wait for 0 from below”如果收到正确的序号为1的报文，为什么需要反馈“ACK”？

仔细考虑可以发现，在当前的假设下（只可能发生位错误），只有一种情况才会发生等待0的时候收到1，就是接收方上一次针对1报文返回给发送方的ACK发生了错误，接收方已经进入等待0的状态，但发送方仍以为接收方没收到所以重传1。因此，这个1是滞后的，如果不返回ACK，那么发送方就会一直重传1从而进入无限循环。

Rdt2.1和Rdt2.0的对比：

> 发送方:
>
> - 为每个分组增加了序列号。
> - 两个序列号就够用，因为使用的是停-等协议。
> - 需要校验ACK/NAK消息是否发生错误。
> - 状态的数量必须翻倍，因为状态必须“记住”“当前”分组的序列号。
>
> 接收方：
>
> - 需要判断分组是否是重复的，当前所处的状态提供了期望接收到的分组的序列号。
> - 注意：接收方无法知道ACK/NAK是否被发送方正确接收到。

进一步思考，我们是否真的需要两种确认消息（ACK+NAK）呢？不一定，我们可以在ACK消息中显式地加入被确认分组的序列号，从而告知发送方当前最后一个被正确接收到的分组。如果发送方发现接收到的ACK是确认前一个分组的时候（重复ACK），就知道当前分组没有被正确接收，进而采取与收到NAK消息相同的动作，也就是重传当前分组。这样就得到Rdt2.2：无NAK消息协议。

![Rdt2.2 FSM片段](http://book.moecode.com/layer4/12.png)



### Rdt3.0

考虑信道既可能发生错误，也可能丢失分组。

如果仍然依照前面“校验和+序列号+ACK+重传”的模式，一旦发生丢包，协议就会一直等下去从而无法工作。如何解决这个问题？发送方应当等待“合理”的事件，如果没有收到ACK，那么就重传。这样又带来问题：如果分组或ACK只是延迟而不是丢失，那么重传就会产生重复，这个有序列号机制可以进行处理。此处也能发现“ACK+NAK”模式是无法使用的，因为没有指明收到的分组的序列号。所以一定要采取带序列号的ACK模式。

我们需要定时器来处理分组丢失的问题。

![Rdt3.0发送方FSM](http://book.moecode.com/layer4/13.png)

Rdt3.0运行示例图如下。

![Rdt3.0示例1](http://book.moecode.com/layer4/14.png)

![Rdt3.0示例2](http://book.moecode.com/layer4/15.png)

注意上图中示例d的情况，在这种情况下，如果在等待ACK0的过程中收到了重复的ACK1，那么发送方是什么都不做的。

Rdt3.0能够正确工作，但是性能是很差的。计算后发现停等协议严重限制了物理资源的利用。

![性能差的计算](http://book.moecode.com/layer4/16.png)

![性能差示意图](http://book.moecode.com/layer4/17.png)



### 流水线机制与滑动窗口协议

为了提高性能，我们需要打破停-等协议，让发送方能够一次发送很多个分组。

流水线协议允许发送方在收到ACK之前连续发送多个分组，那么就需要更大的序列号范围，发送方和接收方也需要更大的存储空间以缓存分组。这样的缓存空间就构成一个数组，一次允许使用的序列号范围就构成了窗口，窗口的尺寸为N就表明最多有N个等待确认的消息。随着协议的运行，窗口在序列号空间内向前滑动，称为滑动窗口协议。

滑动窗口协议分为GBN和SR。



### Go-Back-N协议

分组头部包含k-bit的序列号，则表明可以使用的缓存空间大小为2的k次方。窗口尺寸为N则表明最多允许N个分组未确认。如下图所示，绿色表示已经收到ACK确认的，黄色代表已经发送的但是没有收到确认的，蓝色的表示可用来发送的序列号。白色的表示不可以使用的序列号。

![滑动窗口](http://book.moecode.com/layer4/18.png)

GBN使用的是累积确认机制，也就是说一旦发送方接收到ACK(n)则表示到序列号n（包含n）的所有分组均已经被正确地接收到。这样一来接收方也就只需要设置自己当前期望收到的分组，一个个向前推进即可，也就是说接收方不需要对数据进行缓存，直接收到期望的分组后上交即可。

GBN发送方的FSM如下所示：

![GBN发送方](http://book.moecode.com/layer4/19.png)

如上图所示，一开始由虚线进行初始化，base=nextseqnum=1，表明当前窗口和下一个可用的序号都是1。这时候进入等待状态，一旦收到上层传来的数据，就进行当前序号的判断，如果还有可用的序号（nextseqnum<base+N）那么就使用nextseqnum创建分组，缓存并发送出去，同时依据当前发送的分组是否是窗口的第一个分组（base == nextseqnum）来开启计时器，之后nextseqnum加一。如果没有可用的序列号了，就拒绝上层传来的数据。由此过程可见GBN协议只需要一个计时器来记录窗口的第一个分组是否发生了超时。

一旦（窗口的第一个已经发送出去的分组）发生超时，那么就重启计时器，重新发送所有已经发送但是未确认的分组（从base到nextseqnum-1）。如果接收到了ACK且ACK没有损坏，那么取出ACK的序号，base置为该序号+1，也就是向前滑动一个或若干个窗口 ***** 。如果当前滑动窗口中没有已经发送的数据（base == nextseqnum），那么就停止计时器，否则重启计时器。**由此可见**：计时器记录的不一定是当前窗口第一个分组发送出去的时间，而是该分组发送出去的时刻与前一个分组被确认的时刻中较晚的一个到现在时刻的时间长度。

***** ：为什么取出ACK序号后能够直接加一得到新的base？因为接收方发送的ACK总是当前已经正确接收到的、序列号最高的分组的ACK。这样就表明该序号及之前的分组都已经正确收到。

> 存疑：假设窗口大小是10，刚开始连续发送10个分组，然后接收端连续返回10个ACK，如果ACK(10)跑到了最前面就可能出现下面的情况：发送方收到的ACK的序号小于base，那岂不是滑动窗口往回走了？
>
> 答疑：这里考虑只有一条链路的情况，所以发送报文的时候可以失序（也就是后面的先到了，但是这时候前面没到的一定不会再来了），而返回的ACK不会出现序号大的先于序号小的到的这种情况。也就不会出现滑动窗口回退的情况。

GBN的接收方如下所示：

![接收方](http://book.moecode.com/layer4/20.png)

GBN接收方对于乱序到达的分组会直接丢弃，重新确认序列号最大的、已按序正确到达的分组。

要注意GBN的窗口的最大值为2^k-1（这里k是序列号位长，注意这里不要和SR的2^(k-1)混淆！）。

> 为什么2^k不行？
>
> 考虑极端情况，假设k==5，数组长32，如果窗口长32，这时候一次性发了32个分组，且接收方都接收到了，返回了ACK(0)~ACK(31)，那现在接收方期盼的就是新的0号分组，这时候发送方又检测到超时，那么重发0～31，这时候接收方就会以为这32个是新的分组，这样就出现了大问题。
>
> 如果窗口长度是31呢？那么接收方期望收到的就是31号分组，并不会产生上面的问题。

![GBN示例](http://book.moecode.com/layer4/21.png)

![例题](http://book.moecode.com/layer4/22.png)



### Selective Repeat协议

GBN的缺陷：太多重传分组，网络中会出现很多重传的，浪费资源。改进：

- 接收方对每个分组单独进行确认，设置缓存机制，缓存乱序到达的分组。
- 发送方只重传那些没收到ACK的分组，并为每个分组设置定时器。
- 增加接收方的窗口来缓存收到的分组。

![窗口示意图](http://book.moecode.com/layer4/23.png)

注意：发送方和接收方窗口相互不知道对方所处的状态，这是分布式网络的本质特征。

详细描述SR协议如下图所示。

![SR详细描述](http://book.moecode.com/layer4/24.png)

事实上SR协议会遇到一种问题，如下图所示的两种情况，SR是无法分清的。也就是说接收方不知道当前收到的0号分组是重传的分组还是新来的分组，产生这样的问题根本原因在于序号的循环使用以及窗口相对于整个数组过大。

![SR困境](http://book.moecode.com/layer4/25.png)

可以从技术上解决这个问题，考虑序列号长度为k-bit，那么数组长度为2^k，设发送方窗口长度Ws，接收方窗口长度Wr。假设在某个场景中发送方发送了Ws个分组并全部被接收方收到，接收方也依次返回所有的ACK，接收方的窗口的base就变成了Ws+1（假设都从头开始）。我们需要接收方窗口的最后一个分组不在发送方窗口的范围内，这样发送方发送的最早的分组也就不会被接收方误判为新的分组。这样的约束条件用数学公式来表述就是：

<center>Ws + Wr <= 2^k</center>
一般让Ws == Wr，所以窗口不大于2^(k-1)。



### 面向连接传输协议概述

TCP的特点：

- 点对点的传输，一个发送方对应一个接收方。
- 可靠的、按序的字节流。
- 采用流水线机制，基于TCP拥塞控制和流量控制机制来动态调整窗口尺寸。
- 介于GBN和SR的方法，发送方和接收方都有缓存。
- 面向连接的协议，依据端到端原则，连接的状态只在连接的两端中进行维护，在沿途节点中并不维护状态。TCP连接包括：两台主机上的缓存、连接状态变量、socket等。
- 通过连接能实现双向的数据流传输，所以TCP是全双工的。
- TCP提供流量控制机制和拥塞控制机制

TCP的段结构如下图所示。

![TCP段结构](http://book.moecode.com/layer4/26.png)

- 序列号（sequence number）指的是segment中第一个字节的编号，而不是segment的编号。比如1k字节的数据被分成2组，第二个分组的序号就是500而不是1（从0开始的话）。TCP连接建立的时候，双方随机选择序列号。
- ACK序号（acknowledgement number）是希望接收到的下一个字节的序列号（也不是段序号）。使用累积确认机制：该序列号之前的所有字节均已被正确接收到。从这里可见TCP采用的方法又有GBN的成分。
- 那接收方如何处理乱序到达的Segment呢？TCP规范中没有规定，由TCP的实现者自己做出决策。
- UAPRSF六个标志位，A是用来指示ACK是否有效，RSF用于建立连接。
- Receive Window是接收窗口的大小，代表所愿意接受字节的数目，用于流量控制。

TCP信息传输示例图如下所示。实现简单的telnet功能，接收方收到字符后会回传这个字符。图中显示的是已经建立好连接之后的情景，连接建立的时候双方相互交换了关于序号的信息（序号是随机选择进行初始化的）。注意ACK是期望收到的字节序号，这里的数据长度为1个字节。可见用了两套不同的序号（42 and 79）。

![简单telnet](http://book.moecode.com/layer4/27.png)



### TCP可靠数据传输

TCP在IP层提供的不可靠服务基础上实现可靠数据传输服务，采用流水线机制和累积确认，使用单一的重传计时器。可见在“累积确认”和“使用单一重传定时器”这两点类似于GBN，在“接收方有缓存窗口”这一点类似于SR。

对于TCP来说触发重传的事件有超时和收到重复的ACK。下面的叙述将采用渐进式的方法，先暂时不考虑重复ACK、流量控制、拥塞控制。

先考虑定时器的设置，如何合理设置超时时间呢？有一个重要的参考量RTT，但是RTT是变化的，如果超时时间过短，就会引起不必要的重传，如果过长就会对段的丢失反应慢。

估计RTT：首先测量SampleRTT，也就是测量从段发出去到收到ACK的时间（忽略重传）。但是RTT是变化的，那么我们就要测量多个SampleRTT求平均值，并形成RTT的估计值EstimatedRTT。

<center>EstimateRTT = (1 - a) * EstimatedRTT + a * SampleRTT</center>
指数加权移动平均，a的典型值为0.125。

在EstimatedRTT的基础上加上一个安全边界：

<center>DevRTT = (1 - b) * DevRTT + b * |SampleRTT - EstimatedRTT|</center>
b的典型值为0.25。

定时器超时时间可以设置为：

<center>TimeoutInterval = EstimatedRTT + 4 * DevRTT</center>
TCP发送方的事件有：

![TCP发送方事件](http://book.moecode.com/layer4/28.png)

![TCP发送方伪代码](http://book.moecode.com/layer4/29.png)

TCP传输的例子：

![TCP例1](http://book.moecode.com/layer4/30.png)

![TCP例2](http://book.moecode.com/layer4/31.png)

注意上面图中第二种情况最后接收方返回ACK120，因为是累积确认。

接收方如何产生ACK？

- 如果到达一个按序的段，刚好是expcted sequence number，且这之前的都已经ACK了，那么接收方会采取延迟ACK的措施，等待500ms看有没有下一个分组到达，如果没有下一个的话就发ACK。如果有的话见下面。
- 如果到达一个按序的段，且前一个是刚好发生ACK延迟的，那么立刻发送累积确认ACK。
- 如果到达一个乱序的段，那么立刻发送重复ACK，来强调接收方所期望收到的分组。
- 如果到达一个能部分或完全填充接收数据间隔的段，倘若该报文段起始于间隔的低端，则立即发送ACK。

TCP快速重传机制。如果发生超时，那么TCP的超时时间间隔将加倍，导致其很大，重发丢失的分组之前要等待很长时间。那有什么更快的方法能知道分组丢失（从而进行重传而不用等待那么久）呢？如果某个分组丢失，可能会引发多个重复的ACK。那么可以这样：如果发送方收到对同一个数据的3个ACK，则假定该数据之后的段已经丢失，这样就进行快速重传（在定时器超时之前重传）。快速重传算法如下图所示：

![快速重传算法](http://book.moecode.com/layer4/32.png)



### TCP流量控制

接收方会为TCP连接分配buffer，而上层应用处理buffer中数据的速度可能比较慢。流量控制就是让发送方不会传输太多太快以至于淹没接收方（buffer溢出）。流量控制机制本质上是一种速度匹配机制。TCP流量控制机制如图所示：

![TCP流量控制机制](http://book.moecode.com/layer4/33.png)

注意：如果接收方告知发送方RcvWindow=0，那么发送方该怎么办呢？发送方如果不发数据过去，那么就收不到新的ACK，也就不知道对方何时有空，于是系统陷入死锁。因此在TCP中发送方会发送一段很小的数据（一个字节）过去进行试探。



### TCP连接管理

TCP发送方和接收方在传输数据之前需要建立连接，在建立连接时要初始化TCP变量，包括序号、buffer和流量控制信息。连接的建立过程分三个阶段，称为三次握手。

- 客户主机向服务器发送SYN报文段。注意TCP报文头部有一个SYN标志位。SYN段不携带任何数据，报文段的头部SYN标识位置1，表示需要建立连接，同时传递自己选择的初始序列号。
- 服务器收到SYN报文段，如果同意建立连接，那么这样服务器就会分配缓存，并选择自己的初始序列号，答复SYNACK报文段。
- 客户主机收到SYNACK报文段后答复ACK报文段，这时候SYN标识位不再是1，这时候客户向服务器确认“我收到了你同意我建立连接的报文段”，这个报文段中可以**包含数据**。

![三次握手示意图](http://book.moecode.com/layer4/34.png)

延伸阅读：SYN攻击

TCP的拆除可由客户或服务器发起，不过一般是客户发起。TCP的拆除分为四步：

- 客户向服务器发送FIN控制报文段（FIN也是一个标识位）。
- 服务器收到FIN，回复ACK，关闭连接，发送FIN。
- 客户收到FIN，回复ACK，这时候客户进入“timed wait”的等待状态，如果收到FIN，表明刚刚回复的ACK丢失了，那么就重新发送ACK。
- 服务器收到ACK，连接关闭。

TCP连接管理相应的生命周期如下图所示：

![生命周期](http://book.moecode.com/layer4/35.png)



### 拥塞控制原理

拥塞就是太多主机发送了太多数据或发送速度太快，以至于网络无法处理。拥塞的表现：分组丢失（路由器缓存溢出），分组延迟过大（在路由器缓存中排队）。

可靠数据传输是从个体利益的角度进行，拥塞控制是从群体的角度进行。也要区分好流量控制和拥塞控制。

下面对拥塞的成因和代价进行渐进式讨论：

场景1如下图所示。下左是吞吐率，下右是分组时延。lambda代表速率。

![场景1](http://book.moecode.com/layer4/36.png)

场景2如下两张图所示。lambda仍表示速率，带撇的表示考虑上重传后的实际速率。下面的第二张图考虑三种情况，其中第二第三种情况中由于拥塞是的输出变小，也就是资源被浪费了，而第三种情况的浪费更甚。

![场景2](http://book.moecode.com/layer4/37.png)

![场景2讨论](http://book.moecode.com/layer4/38.png)

场景中3如下两张图所示。考虑多跳多主机且有超时重传的情景，考虑某个分组经过多跳到了某个路由器后发生了丢包，那么前面付出的资源就都浪费了，考虑趋于极限的极端情况，就会导致网络的输出趋于0.

![场景3](http://book.moecode.com/layer4/39.png)

![场景3讨论](http://book.moecode.com/layer4/40.png)

如何进行拥塞控制呢？

- 端到端的拥塞控制，网络层不需要显式地提供支持，端系统通过观察loss、delay等网络行为判断是否发生拥塞。TCP采取了这种方法。
- 网络辅助的拥塞控制，路由器向发送方显式反馈网络拥塞信息，依赖于简单的拥塞指示，来指示发送方应该采取怎样的速率。ATM采用了这种方法。

现在考虑网络辅助的拥塞控制，另一种放到下一节。

ATM ABR拥塞控制。available bit rate。是一种“弹性服务”：如果发送方发现路径上负载比较低，那么就尽可能地使用可用的带宽，如果发现路径拥塞，那么就将发送速率降到最低保障速率。具体的实现方式见MOOC，不属于考试范围。



### TCP拥塞控制机制

设置变量叫做拥塞窗口CongWin，LastByteSent - LastByteAcked <= CongWin，于是速率约为CongWin除以RTT。动态调整CongWin来改变发送速率，CongWin能反映所感知到的网络拥塞。

如何感知网络拥塞呢？发生超时或3个重复ACK的话就表明网络拥塞。

加性增，乘性减（AIMD）。原理是逐渐增加发送速率，谨慎探测可用带宽，直到发生loss事件（超时/3个重复ACK）。

慢启动（SS）。刚开始的时候可用带宽可能远远高于初始速率，所以希望能够快速增长。就是当连接开始时，使用指数型增长。其实就是对于每一个ACK的段，拥塞窗口都加一（这样就实现了翻倍），如下图所示。

![慢启动](http://book.moecode.com/layer4/41.png)

指数型增长切换到线性增长的切换点是threshold。Loss事件发生时，Threshold设为Loss事件前CongWin值的一半。

在TCP的早期版本（Tahoe），一旦发生Loss 事件，CongWin就变成1。这里对于超时和3个重复ACK这两种情况并不加以区分。实际上这样显得太过于保守，所以TCP新的版本采用了Reno算法。

Reno算法中，如果发生收到3个重复ACK，那么CongWin变为新门限值+3MSS，线性增长；如果发生超时，那么CongWin变为1，指数增长至门限后变为线性增长。两种情况的Threshold都是发生Loss事件的CongWin的一半。为什么要加上这样的区分呢？收到3个ACK表示网络至少还能传输一些Segment，而超时表明网络发生的拥塞更严重。

注意名称：慢启动指的是指数增长，拥塞避免指的是线性增长。

![TCP拥塞控制算法总结](http://book.moecode.com/layer4/42.png)

![拥塞控制列表](http://book.moecode.com/layer4/43.png)

注意上面表格的前两行中采取的动作，是在收到一个ACK时发生的，而不是一个RTT时发生的，所以增加的量要分清楚。

![Reno算法伪代码](http://book.moecode.com/layer4/44.png)

注意图中倒数第二行应该还要加三，MOOC与我校课程有出入。

![一道例题](http://book.moecode.com/layer4/45.png)



### TCP性能分析

TCP吞吐率最简单的估计如下图一所示，图二为一计算举例，图三为计算吞吐率与丢包率的关系。注意图二中乘以8的原因是Gbps指的是bit，而MSS的单位根据题目看来采用了Byte。**务必注意bit和Byte的区分**！

![吞吐率估计](http://book.moecode.com/layer4/46.png)

![计算举例](http://book.moecode.com/layer4/47.png)

![吞吐率与丢包率](http://book.moecode.com/layer4/48.png)

TCP的公平性。如果K个TCP连接共享瓶颈带宽R，那么每个连接的平均速率为R/K。为什么是公平的呢？考虑2个主机的情况如下图所示。横坐标表示连接1的吞吐率，纵坐标表示连接2的吞吐率，深红色细线表示二者吞吐率相等，深红色粗线表示二者之和限制在R以内。一开始具有某个点如图中右下角所示，二者线性增加超过粗线就发生超时，于是乘性减也就是那个点与原点连线的中点，这样下去工作状态就会收敛到中间细线附近。这表明TCP的公平性。

![公平性分析](http://book.moecode.com/layer4/49.png)

如果TCP和UDP共存时其实会产生不公平。分析如图所示。

![共存时的公平性](http://book.moecode.com/layer4/50.png)
